{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c30607f1-9ca7-41d4-8f40-1551d06efac9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e515a3be-2de5-42ea-9765-5b89508ab16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd 1_Detection_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448b5b7c-bfa0-47fd-b213-08ddcc1ade49",
   "metadata": {},
   "source": [
    "### Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8837249f-8980-4368-a50c-8dd21b0f940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run (optional)\n",
    "# YOLOv5l, 1280x1280 input size, pretrained\n",
    "!python train.py --project \"/root/autodl-tmp/DT_SegNet/Detection_Model_Output\" --img 1280 --data dtsegnet.yaml --cache --batch-size -1 --epochs 2 --weights yolov5l6.pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42106370-3380-4b3f-ac04-69bb6f2e901b",
   "metadata": {},
   "source": [
    "### Backbone selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b8aa97-4dfc-4713-9f87-93729395c90a",
   "metadata": {
    "id": "GFAUgWVwO0ar"
   },
   "source": [
    "#### 640x640 input size, not pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1152d7-2b9d-4d8b-a8df-f7f249f05d73",
   "metadata": {
    "id": "GRUJXaBUI6NS"
   },
   "outputs": [],
   "source": [
    "# YOLOv5n, 640x640 input size, not pretrained\n",
    "!python train.py --project \"/root/autodl-tmp/DT_SegNet/Detection_Model_Output\" --img 640 --data dtsegnet.yaml --cache --batch-size -1 --epochs 9999 --patience 150 --cfg yolov5n.yaml --weights ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b9b31-e695-417b-8669-5c0ad2b39dd7",
   "metadata": {
    "id": "EtHprp5AOUFq"
   },
   "outputs": [],
   "source": [
    "# YOLOv5s, 640x640 input size, not pretrained\n",
    "!python train.py --project \"/root/autodl-tmp/DT_SegNet/Detection_Model_Output\" --img 640 --data dtsegnet.yaml --cache --batch-size -1 --epochs 9999 --patience 150 --cfg yolov5s.yaml --weights ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290345be-fde6-432d-8e04-e6d24ea7af98",
   "metadata": {
    "id": "QOsRDPKcOUag"
   },
   "outputs": [],
   "source": [
    "# YOLOv5m, 640x640 input size, not pretrained\n",
    "!python train.py --project \"/root/autodl-tmp/DT_SegNet/Detection_Model_Output\" --img 640 --data dtsegnet.yaml --cache --batch-size -1 --epochs 9999 --patience 150 --cfg yolov5m.yaml --weights ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d165c28-fc51-49a4-8e31-38827d813bef",
   "metadata": {
    "id": "5WNeYeiyOUUT"
   },
   "outputs": [],
   "source": [
    "# YOLOv5l, 640x640 input size, not pretrained\n",
    "!python train.py --project \"/root/autodl-tmp/DT_SegNet/Detection_Model_Output\" --img 640 --data dtsegnet.yaml --cache --batch-size -1 --epochs 9999 --patience 150 --cfg yolov5l.yaml --weights ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d70645-1b2d-42e6-9b8c-38bca6f18232",
   "metadata": {
    "id": "lm9sibZxO2ur"
   },
   "source": [
    "#### 1280x1280 input size, not pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de315c25-885b-4a08-a504-b425da6b3a47",
   "metadata": {
    "id": "MARwOshsOslf"
   },
   "outputs": [],
   "source": [
    "# YOLOv5n, 1280x1280 input size, not pretrained\n",
    "!python train.py --project \"/root/autodl-tmp/DT_SegNet/Detection_Model_Output\" --img 1280 --data dtsegnet.yaml --cache --batch-size -1 --epochs 9999 --patience 150 --cfg yolov5n.yaml --weights ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ccb1f-f823-4b6b-8bf9-2fab58fcfb15",
   "metadata": {
    "id": "SguoYPPAOs2P"
   },
   "outputs": [],
   "source": [
    "# YOLOv5s, 1280x1280 input size, not pretrained\n",
    "!python train.py --project \"/root/autodl-tmp/DT_SegNet/Detection_Model_Output\" --img 1280 --data dtsegnet.yaml --cache --batch-size -1 --epochs 9999 --patience 150 --cfg yolov5s.yaml --weights ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c11433-69ee-48dd-a58c-53c688642da0",
   "metadata": {
    "id": "960JmZhaOs_g"
   },
   "outputs": [],
   "source": [
    "# YOLOv5m, 1280x1280 input size, not pretrained\n",
    "!python train.py --project \"/root/autodl-tmp/DT_SegNet/Detection_Model_Output\" --img 1280 --data dtsegnet.yaml --cache --batch-size -1 --epochs 9999 --patience 150 --cfg yolov5m.yaml --weights ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c103e-3751-4bcb-ade6-0c98173c4aaa",
   "metadata": {
    "id": "eCQOAo_TOtH0"
   },
   "outputs": [],
   "source": [
    "# YOLOv5l, 1280x1280 input size, not pretrained\n",
    "!python train.py --project \"/root/autodl-tmp/DT_SegNet/Detection_Model_Output\" --img 1280 --data dtsegnet.yaml --cache --batch-size -1 --epochs 9999 --patience 150 --cfg yolov5l.yaml --weights ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d3740-4f84-4ef5-a566-fe87a274f339",
   "metadata": {
    "id": "xZ10FdHPO-pm"
   },
   "source": [
    "#### 1280x1280 input size, pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c80491-dfdb-40e2-bbf1-11be5153aa9c",
   "metadata": {
    "id": "F6JBnmanOthu"
   },
   "outputs": [],
   "source": [
    "# YOLOv5n, 1280x1280 input size, pretrained\n",
    "!python train.py --project \"/root/autodl-tmp/DT_SegNet/Detection_Model_Output\" --img 1280 --data dtsegnet.yaml --cache --batch-size -1 --epochs 9999 --patience 150 --weights yolov5n6.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd716494-a857-4133-b3ce-948a96de909f",
   "metadata": {
    "id": "Yy7N8q38OtsM"
   },
   "outputs": [],
   "source": [
    "# YOLOv5s, 1280x1280 input size, pretrained\n",
    "!python train.py --project \"/root/autodl-tmp/DT_SegNet/Detection_Model_Output\" --img 1280 --data dtsegnet.yaml --cache --batch-size -1 --epochs 9999 --patience 150 --weights yolov5s6.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951af9bd-d670-449f-9398-91bd7695a6b9",
   "metadata": {
    "id": "wlAXKbLgOt5c"
   },
   "outputs": [],
   "source": [
    "# YOLOv5m, 1280x1280 input size, pretrained\n",
    "!python train.py --project \"/root/autodl-tmp/DT_SegNet/Detection_Model_Output\" --img 1280 --data dtsegnet.yaml --cache --batch-size -1 --epochs 9999 --patience 150 --weights yolov5m6.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674ee45-2425-4a5b-ab50-0fe7c7e11d46",
   "metadata": {
    "id": "RABgULgeOuE6"
   },
   "outputs": [],
   "source": [
    "# YOLOv5l, 1280x1280 input size, pretrained\n",
    "!python train.py --project \"/root/autodl-tmp/DT_SegNet/Detection_Model_Output\" --img 1280 --data dtsegnet.yaml --cache --batch-size -1 --epochs 9999 --patience 150 --weights yolov5l6.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c1ca63-af0e-421c-84f4-d4f86ab04e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599b968-0e6e-476f-a3d1-da4c09b0480c",
   "metadata": {},
   "source": [
    "## Generate dataset for segmentation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ac0fe-6ab7-420b-b334-ebbac91e350e",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c7344-3ece-4a7a-bf3d-b9225167e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21e885e-cfbf-41d2-bafb-fb1e95a0c2f5",
   "metadata": {},
   "source": [
    "### Convert Detection Dataset to Segmentation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09456517-5f08-4a78-a186-0c0d5395ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read YOLO format txt label, and perform dilation\n",
    "def read_labels(label_dir, img, dilation = 1.5):\n",
    "    data = pd.read_csv(str(label_dir), sep=\" \", header=None,\n",
    "                    names=[\"class\", \"x_center\", \"y_center\", \"width\", \"height\"])\n",
    "    img_x, img_y = img.size\n",
    "    data['x0'] = ((data['x_center'] - dilation * data['width'] / 2) * img_x).astype(\"int\")\n",
    "    data['x1'] = ((data['x_center'] + dilation * data['width'] / 2) * img_x).astype(\"int\")\n",
    "    data['y0'] = ((data['y_center'] - dilation * data['height'] / 2) * img_y).astype(\"int\")\n",
    "    data['y1'] = ((data['y_center'] + dilation * data['height'] / 2) * img_y).astype(\"int\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf10d44-6eb7-4171-ab70-a645a7b448ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dirs = ['train', 'test', 'val']\n",
    "\n",
    "data_dir = Path('/root/autodl-tmp/DT_SegNet/Dataset/')\n",
    "label_dir = Path('/root/autodl-tmp/DT_SegNet/Dataset/segmentation_labels')\n",
    "\n",
    "output_root = Path('/root/autodl-tmp/DT_SegNet/Dataset/Segmentation_Dataset/')\n",
    "output_data_dir = output_root / 'images'\n",
    "output_label_dir = output_root / 'labels'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4db561-1589-4b39-9e30-3be36ece45aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cset in sub_dirs:\n",
    "    (output_data_dir/cset).mkdir(parents=True, exist_ok=True)\n",
    "    (output_label_dir/cset).mkdir(parents=True, exist_ok=True)\n",
    "    for img_path in list((data_dir/cset).glob('**/*.png')):\n",
    "        print(f'Processing {str(img_path)}')\n",
    "\n",
    "        # process cropped image\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert(\"L\")\n",
    "        # print(img.format, img.size, img.mode)\n",
    "        labels = read_labels(img_path.with_suffix('.txt'), img)\n",
    "        with tqdm(total=len(labels)) as pbar:\n",
    "            for index, r in labels.iterrows():\n",
    "                box = (r.x0, r.y0, r.x1, r.y1)\n",
    "                region = img.crop(box)\n",
    "                # region.show()\n",
    "                croped_savepath = output_data_dir / cset / f'{img_path.stem}_{index}{img_path.suffix}'\n",
    "                # print(croped_savepath, box)\n",
    "                region.save(croped_savepath)\n",
    "                pbar.update(1)\n",
    "        \n",
    "        # process cropped label\n",
    "        img = Image.open(label_dir / f'{img_path.stem}{img_path.suffix}')\n",
    "        img = img.convert(\"P\")\n",
    "        # print(img.format, img.size, img.mode)\n",
    "        with tqdm(total=len(labels)) as pbar:\n",
    "            for index, r in labels.iterrows():\n",
    "                box = (r.x0, r.y0, r.x1, r.y1)\n",
    "                region = img.crop(box)\n",
    "                # region.show()\n",
    "                croped_savepath = output_label_dir / cset / f'{img_path.stem}_{index}{img_path.suffix}'\n",
    "                # print(croped_savepath, box)\n",
    "                region.save(croped_savepath)\n",
    "                pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a27104-c339-47e1-9f11-8202050a586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cset in sub_dirs:\n",
    "    datas = pd.DataFrame({\n",
    "        'data': [f'images/{cset}/{x.name}' for x in sorted((output_data_dir/cset).glob('*.png'))],\n",
    "        'label': [f'labels/{cset}/{x.name}' for x in sorted((output_label_dir/cset).glob('*.png'))],\n",
    "    })\n",
    "\n",
    "    datas.to_csv(output_root / f'{cset}.txt', header=None, index=None, sep=' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270dcaea-8ea0-4d6d-82ab-11c56548cf08",
   "metadata": {},
   "source": [
    "### Convert Detection Dataset to Segmentation Dataset (KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec481d-779c-4bde-a3db-142d83da5c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_ids = [0, 1, 2, 3, 4]\n",
    "sub_dirs = ['train', 'val']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031be5cf-7e80-4dd6-9b03-fdbeea73b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kf_id in kf_ids:\n",
    "\n",
    "    data_dir = Path(f'/root/autodl-tmp/DT_SegNet/Dataset/KFold/{kf_id}')\n",
    "    label_dir = Path(f'/root/autodl-tmp/DT_SegNet/Dataset/segmentation_labels')\n",
    "\n",
    "    output_root = Path(f'/root/autodl-tmp/DT_SegNet/Dataset/SD_KF/{kf_id}')\n",
    "    output_data_dir = output_root / 'images'\n",
    "    output_label_dir = output_root / 'labels'\n",
    "    \n",
    "    for cset in sub_dirs:\n",
    "        (output_data_dir/cset).mkdir(parents=True, exist_ok=True)\n",
    "        (output_label_dir/cset).mkdir(parents=True, exist_ok=True)\n",
    "        for img_path in list((data_dir/cset).glob('**/*.png')):\n",
    "            print(f'Processing {str(img_path)}')\n",
    "\n",
    "            # process cropped image\n",
    "            img = Image.open(img_path)\n",
    "            img = img.convert(\"L\")\n",
    "            # print(img.format, img.size, img.mode)\n",
    "            labels = read_labels(img_path.with_suffix('.txt'), img)\n",
    "            with tqdm(total=len(labels)) as pbar:\n",
    "                for index, r in labels.iterrows():\n",
    "                    box = (r.x0, r.y0, r.x1, r.y1)\n",
    "                    region = img.crop(box)\n",
    "                    # region.show()\n",
    "                    croped_savepath = output_data_dir / cset / f'{img_path.stem}_{index}{img_path.suffix}'\n",
    "                    # print(croped_savepath, box)\n",
    "                    region.save(croped_savepath)\n",
    "                    pbar.update(1)\n",
    "\n",
    "            # process cropped label\n",
    "            img = Image.open(label_dir / f'{img_path.stem}{img_path.suffix}')\n",
    "            img = img.convert(\"P\")\n",
    "            # print(img.format, img.size, img.mode)\n",
    "            with tqdm(total=len(labels)) as pbar:\n",
    "                for index, r in labels.iterrows():\n",
    "                    box = (r.x0, r.y0, r.x1, r.y1)\n",
    "                    region = img.crop(box)\n",
    "                    # region.show()\n",
    "                    croped_savepath = output_label_dir / cset / f'{img_path.stem}_{index}{img_path.suffix}'\n",
    "                    # print(croped_savepath, box)\n",
    "                    region.save(croped_savepath)\n",
    "                    pbar.update(1)\n",
    "                \n",
    "    for cset in sub_dirs:\n",
    "        datas = pd.DataFrame({\n",
    "            'data': [f'images/{cset}/{x.name}' for x in sorted((output_data_dir/cset).glob('*.png'))],\n",
    "            'label': [f'labels/{cset}/{x.name}' for x in sorted((output_label_dir/cset).glob('*.png'))],\n",
    "        })\n",
    "\n",
    "        datas.to_csv(output_root / f'{cset}.txt', header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046364c-f2d0-4947-a28a-39a64695e98b",
   "metadata": {},
   "source": [
    "## Train segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dfda74-1bbc-4112-8c33-270c59bdc6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('/root/autodl-tmp/DT_SegNet/Segmentation_Model_Output').mkdir(parents=True, exist_ok=True)\n",
    "Path('/root/autodl-tmp/DT_SegNet/Baseline_Model_Output').mkdir(parents=True, exist_ok=True)\n",
    "%cd 3_Segmentation_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e2e58-be54-478a-bb45-7a55a4401072",
   "metadata": {},
   "source": [
    "### Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d2fd5-5c65-47d7-a9a9-a7056b3176cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --iters 200 --config configs/dtsegnet/segformer_b1.yml --do_eval --use_vdl --save_interval 100 --keep_checkpoint_max 1 --save_dir \"/root/autodl-tmp/DT_SegNet/Segmentation_Model_Output/B1\" > \"/root/autodl-tmp/DT_SegNet/Segmentation_Model_Output/B1.log\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd3f31e-d28d-4637-b8ab-1eba5da0aad1",
   "metadata": {},
   "source": [
    "### Backbone selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be31e8d6-b44b-4e16-97ea-d89f55e1d985",
   "metadata": {
    "id": "lCbiNIyhSCPJ"
   },
   "outputs": [],
   "source": [
    "# SegFormer B0\n",
    "!python train.py --config configs/dtsegnet/segformer_b0.yml --do_eval --use_vdl --save_interval 200 --save_dir \"/root/autodl-tmp/DT_SegNet/Segmentation_Model_Output/B0\" > \"/root/autodl-tmp/DT_SegNet/Segmentation_Model_Output/B0.log\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5d4f5-b875-46e3-b9a5-ecc355379313",
   "metadata": {
    "id": "F8fiqCRWSDXd"
   },
   "outputs": [],
   "source": [
    "# SegFormer B1\n",
    "!python train.py --config configs/dtsegnet/segformer_b1.yml --do_eval --use_vdl --save_interval 200 --save_dir \"/root/autodl-tmp/DT_SegNet/Segmentation_Model_Output/B1\" > \"/root/autodl-tmp/DT_SegNet/Segmentation_Model_Output/B1.log\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074a018-0d71-4522-aa2b-9acc1395815a",
   "metadata": {},
   "source": [
    "### Train baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563109df-b63d-4e3f-a415-2d83b383958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SegFormer B0\n",
    "!python train.py --config configs/baseline/segformer_b0.yml --do_eval --use_vdl --save_interval 100  --keep_checkpoint_max 1 --save_dir \"/root/autodl-tmp/DT_SegNet/Baseline_Model_Output/segformer_b0\" > \"/root/autodl-tmp/DT_SegNet/Baseline_Model_Output/segformer_b0.log\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6a1f37-78d8-4a45-af8b-807c964236d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SegFormer B1\n",
    "!python train.py --config configs/baseline/segformer_b1.yml --do_eval --use_vdl --save_interval 100  --keep_checkpoint_max 1 --save_dir \"/root/autodl-tmp/DT_SegNet/Baseline_Model_Output/segformer_b1\" > \"/root/autodl-tmp/DT_SegNet/Baseline_Model_Output/segformer_b1.log\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96cfd6e-bc28-4d7d-9363-2ff204611da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net\n",
    "!python train.py --config configs/baseline/unet.yml --do_eval --use_vdl --save_interval 100 --keep_checkpoint_max 1 --save_dir \"/root/autodl-tmp/DT_SegNet/Baseline_Model_Output/unet\" > \"/root/autodl-tmp/DT_SegNet/Baseline_Model_Output/unet.log\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16b044-e549-4c09-9af9-bfdbb187c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet 3+\n",
    "!python train.py --config configs/baseline/unet_3plus.yml --do_eval --use_vdl --save_interval 100  --keep_checkpoint_max 1 --save_dir \"/root/autodl-tmp/DT_SegNet/Baseline_Model_Output/unet_3plus\" > \"/root/autodl-tmp/DT_SegNet/Baseline_Model_Output/unet_3plus.log\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01404d8d-15db-4988-adab-7869ed3a65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepLabV3P\n",
    "!python train.py --config configs/baseline/deeplabv3p_resnet50.yml --do_eval --use_vdl --save_interval 100  --keep_checkpoint_max 1 --save_dir \"/root/autodl-tmp/DT_SegNet/Baseline_Model_Output/deeplabv3p_resnet50\" > \"/root/autodl-tmp/DT_SegNet/Baseline_Model_Output/deeplabv3p_resnet50.log\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
